<!-- vim: set filetype=docbkxml shiftwidth=2 autoindent expandtab tw=77 : -->

<chapter id="concurrent" revision="alpha;beta">
  <title>Concurrent and multicore programming</title>

  <para>As we write this book, the landscape of CPU architecture is
    changing more rapidly than it has in decades.  </para>

  <sect1>
    <title>Defining concurrency and parallelism</title>

    <para>A <emphasis>concurrent</emphasis> program needs to perform
      several possibly unrelated tasks at the same time.  Consider the
      example of a virtual world: a server is typically composed of
      dozens of components, each of which has complicated interactions
      with the outside world.  One component might handle multi-user
      chat; another with evaluating scripts attached to objects; while
      another processes monetary transactions.</para>

    <para>The correct operation of a concurrent program does not
      require multiple cores, though they may improve performance and
      responsiveness.</para>

    <para>In contrast, a <emphasis>parallel</emphasis> program solves
      a single problem.  Consider a financial model that attempts to
      predict the next minute of fluctuations in the price of a single
      stock.  If we want to apply this model to every stock listed on
      an exchange, to estimate which ones we should buy and sell, we
      hope to get an answer more quickly if we run the model on five
      hundred cores than if we use just one. (As this suggests, a
      parallel program does not usually depend on the presence of
      multiple cores to work correctly.)</para>

    <para>Another useful distinction between concurrent and parallel
      programs lies in their interaction with the outside world.  By
      definition, a concurrent program deals continuously with
      networking protocols, databases, and the like.  A typical
      parallel program is likely to be more focused: it streams data
      in, crunches it for a while (with little further I/O), then
      streams data back out.</para>

    <para>In this chapter, we will concern ourselves with concurrent
      and parallel programs that operate within the boundaries of a
      single operating system process.</para>
  </sect1>

  <sect1>
    <title>Concurrent programming with threads</title>

    <para>As a building block for concurrent programs, most
      programming languages provide a way of creating multiple
      independent <emphasis>threads of control</emphasis>.  Haskell is
      no exception, though programming with threads in Haskell looks
      somewhat different than in other languages.</para>

    <para>In Haskell, a thread is an <type>IO</type> action that
      executes independently from other threads.  To create a thread,
      we import the <code>Control.Concurrent</code> module and use the
      <function>forkIO</function> function.</para>

    &forkIO.ghci:forkIO;

    <para>The new thread starts to execute almost immediately, and the
      thread that created it continues to execute concurrently.</para>

    <sect2>
      <title>Threads are nondeterministic</title>

      <para>The runtime component of &GHC; does not specify an order
	in which it executes threads.  As a result, in our example
	above, the file <filename>xyzzy</filename> created by the new
	thread <emphasis>may or may not</emphasis> have been created
	by the time the original thread checks for its existence. If
	we try this example once, then remove
	<filename>xyzzy</filename> and try again, we may get a
	different result the second time.</para>
    </sect2>

    <sect2>
      <title>Hiding latency</title>

      <para>Suppose we have a large file to compress and write to
	disk, but we want to handle a user's input quickly enough that
	they will perceive our program as responding immediately.  If
	we use <function>forkIO</function> to write the file out in a
	separate thread, we can do both simultaneously.</para>

      &Compressor.hs:module;

      <para>Because we're using lazy <type>ByteString</type> I/O here,
	all we really do in the main thread is open the file.  The
	actual reading occurs on demand in the other thread.</para>

      <para>The use of <code>flip catch print</code> gives us a cheap
	way to print an error message if the user enters the name of a
	file that does not exist.</para>
    </sect2>
  </sect1>

  <sect1>
    <title>Simple communication between threads</title>

    <para>The simplest way to share information between two threads is
      to let them both use a variable.  In our file compression
      example, the <function>main</function> thread shares both the
      name of a file and its contents with the other thread.  Because
      Haskell data is immutable by default, this poses no risks:
      neither thread can modify the other's view of the file's name or
      contents.</para>

    <para>We often need to have threads actively communicate with each
      other. For example, &GHC; does not provide a way for one thread
      to find out whether another is still executing, has completed,
      or has crashed<footnote>
	<para>As we will show later, &GHC; threads are extraordinarily
	  lightweight.  If the runtime were to provide a way to check
	  the status of every thread, the overhead of every thread
	  would increase, even if this information were never
	  used.</para>
      </footnote>.  However, it provides a <emphasis>synchronizing
	variable</emphasis> type, the <type>MVar</type>, which we can
      use for this purpose.</para>

    <para>An <type>MVar</type> acts like a single-element box: it can
      be either full or empty.  We can put something into the box,
      making it full, or take something out, making it empty.</para>

    &mvar.ghci:MVar;

    <para>If we try to put a value into an <type>MVar</type> that is
      already full, our thread is put to sleep until another thread
      takes the value out.  Similarly, if we try to take a value from
      an empty <type>MVar</type>, our thread is put to sleep until
      some other thread puts a value in.</para>

    &MVarExample.hs:communicate;

    <para>The <function>newEmptyMVar</function> function has a
      descriptive name.  To create an <type>MVar</type> that starts
      out non-empty, we'd use <function>newMVar</function>.</para>

    &mvar.ghci:new;

    <para>Let's run our example in &ghci;.</para>

    &mvar.ghci:communicate;

    <para>If you're coming from a background of concurrent programming
      in a traditional language, you can think of an <type>MVar</type>
      as being useful for two familiar purposes.</para>

    <itemizedlist>
      <listitem>
	<para>Sending a message from one thread to another, e.g. a
	  notification.</para>
      </listitem>
      <listitem>
	<para>Providing <emphasis>mutual exclusion</emphasis> for a
	  piece of mutable data that is shared among threads.  We put
	  the data into the <type>MVar</type> when it is not being
	  used by any thread, and one thread takes it out temporarily
	  to read or modify it.</para>
      </listitem>
    </itemizedlist>

  </sect1>

  <sect1>
    <title>The main thread and waiting for other threads</title>

    <para>&GHC;'s runtime system treats the program's original thread
      of control differently from other threads.  When this thread
      finishes executing, the runtime system considers the program as
      a whole to have completed.  If any other threads are executing
      at the time, they are terminated.</para>

    <para>As a result, when we have long-running threads that must not
      be killed, we must make special arrangements to ensure that the
      main thread doesn't complete until the others do.  Let's develop
      a small library that makes this easy to do.</para>

    &NiceFork.hs:header;

    <para>We keep our <type>ThreadManager</type> type abstract using
      the usual recipe: we wrap it in a &newtype;, and prevent clients
      from creating values of this type.  Among our module's exports,
      we list the type constructor and the <type>IO</type> action that
      constructs a manager, but we do not export the data
      constructor.</para>

    &NiceFork.hs:module;

    <para>For the implementation of <type>ThreadManager</type>, we
      maintain a map from thread ID to thread state.  We'll refer to
      this as the <emphasis>thread map</emphasis>.</para>

    &NiceFork.hs:ThreadManager;

    <para>We have two levels of <type>MVar</type> use here.  We keep
      the <type>Map</type> in an <type>MVar</type>.  This lets us
      <quote>modify</quote> the map by replacing it with a new
      version.  We also ensure that any thread that uses the
      <type>Map</type> will see a consistent view of it.</para>

    <para>For each thread that we manage, we maintain an
      <type>MVar</type>.  A per-thread <type>MVar</type> starts off
      empty, which indicates that the thread is executing.  When the
      thread finishes or is killed by an uncaught exception, we put
      this information into the <type>MVar</type>.</para>

    <para>To create a thread and watch its status, we must perform a
      little bit of book-keeping.</para>

    &NiceFork.hs:forkManaged;

    <sect2>
      <title>Safely modifying an MVar</title>

      <para>The <function>modifyMVar</function> function that we used
	in <function>forkManaged</function> above is very useful: it's
	a safe combination of <function>takeMVar</function> and
	<function>putMVar</function>.</para>

      &mvar.ghci:modifyMVar;

      <para>It takes the value from an <type>MVar</type>, and passes
	it to a function.  This function can both generate a new value
	and return a result.  If the function throws an exception,
	<function>modifyMVar</function> puts the original value back
	into the <type>MVar</type>, otherwise it puts the new value
	in. It returns the other element of the function as its own
	result.</para>

      <para>When we use <function>modifyMVar</function> instead of
	manually managing an <type>MVar</type> with
	<function>takeMVar</function> and
	<function>putMVar</function>, we avoid two common kinds of
	concurrency bug.</para>

      <itemizedlist>
	<listitem>
	  <para>Forgetting to put a value back into an
	    <type>MVar</type>.  This can result in
	    <emphasis>deadlock</emphasis>, in which some thread waits
	    forever on an <type>MVar</type> that will never have a
	    value put into it.</para>
	</listitem>
	<listitem>
	  <para>Failure to account for the possibility that an
	    exception might be thrown, disrupting the flow of a piece
	    of code. This can result in a call to
	    <function>putMVar</function> that
	    <emphasis>should</emphasis> occur not actually happening,
	    again leading to deadlock.</para>
	</listitem>
      </itemizedlist>
    
      <para>Because of these nice safety properties, it's wise to use
	<function>modifyMVar</function> whenever possible.</para>

    </sect2>

    <sect2>
      <title>Safe resource management: a good idea, and easy
	besides</title>

      <para>We can the take the pattern that
	<function>modifyMVar</function> follows, and apply it to many
	other resource management situations.  Here are the steps of
	the pattern.</para>

      <orderedlist>
	<listitem>
	  <para>Acquire a resource.</para>
	</listitem>
	<listitem>
	  <para>Pass the resource to a function that will do something
	    with it.</para>
	</listitem>
	<listitem>
	  <para>Always release the resource, even if the function
	    throws an exception. If that occurs, rethrow the exception
	    so it can be caught by application code.</para>
	</listitem>
      </orderedlist>

      <para>Safety aside, this approach has another benefit: it can
	make our code shorter and easier to follow.  As we can see
	from looking at <function>forkManaged</function> above,
	Haskell's lightweight syntax for anonymous functions makes
	this style of coding visually unobtrusive.</para>

      <para>Here's the definition of <function>modifyMVar</function>,
	so that you can see a specific form of this pattern.</para>

      &ModifyMVar.hs:modifyMVar;

      <para>You should easily be able to adapt this to your particular
	needs, whether you're working with network connections,
	database handles, or data managed by a C library.</para>
    </sect2>

    <sect2>
      <title>Finding the status of a thread</title>

      <para>Our <function>getStatus</function> function tells us the
	current state of a thread.  If the thread is no longer managed
	(or was never managed in the first place), it returns
	<code>Nothing</code>.</para>

      &NiceFork.hs:getStatus;

      <para>If the thread is still running, it returns <code>Just
	  Running</code>. Otherwise, it indicates why the thread
	terminated, <emphasis>and</emphasis> stops managing the
	thread.</para>

      <para>If the <function>tryTakeMVar</function> function finds
	that the <type>MVar</type> is empty, it returns
	<code>Nothing</code> immediately instead of blocking.</para>

      &mvar.ghci:tryTakeMVar;

      <para>Otherwise, it extracts the value from the
	<type>MVar</type> as usual.</para>

      <para>The <function>waitFor</function> function behaves
	similarly, but instead of returning immediately, it blocks
	until the given thread terminates before returning.</para>

      &NiceFork.hs:waitFor;

      <para>It first extracts the <type>MVar</type> that holds the
	thread's state, if it exists.  The <type>Map</type> type's
	<function>updateLookupWithKey</function> function is useful:
	it combines looking up a key with modifying or removing the
	value.</para>

      &niceFork.ghci:updateLookupWithKey;

      <para>In this case, we want to always remove the
	<type>MVar</type> holding the thread's state if it is present,
	so that our thread manager will no longer be managing the
	thread.  If there was a value to extract, we take the thread's
	exit status from the <type>MVar</type> and return it.</para>

      <para>Our final useful function simply waits for all currently
	managed threads to complete, and ignores their exit
	statuses.</para>

      &NiceFork.hs:waitAll;
    </sect2>

    <sect2>
      <title>Writing tighter code</title>

      <para>Our definition of <function>waitFor</function> above is a
	little unsatisfactory, because we're performing more or less
	the same case analysis in two places: inside the function
	called by <function>modifyMVar</function>, and again on its
	return value.</para>

      <para>Sure enough, we can apply a function that we came across
	earlier to eliminate this duplication.  The function in
	question is <function>join</function>, from the
	<code>Control.Monad</code> module.</para>

      &niceFork.ghci:join;

      <para>The trick here is to see that we can get rid of the second
	&case; expression by having the first one return the
	<type>IO</type> action that we should perform once we return
	from <function>modifyMVar</function>.  We'll use
	<function>join</function> to execute the action.</para>

      &NiceFork.hs:waitFor2;

      <para>This is an interesting idea: we can create a monadic
	function or action in pure code, then pass it around until we
	end up in a monad where we can use it.  This can be a nimble
	way to write code, once we develop an eye for when it makes
	sense.</para>
    </sect2>
  </sect1>

  <sect1>
    <title>Communicating over channels</title>

    <para>For one-shot communications between threads, an
      <type>MVar</type> is perfectly good.  Another type,
      <type>Chan</type>, provides a one-way communication channel.
      Here is a simple example of its use.</para>

    &Chan.hs:chanExample;

    <para>If a <type>Chan</type> is empty,
      <function>readChan</function> blocks until there is a value to
      read.  The <function>writeChan</function> function never blocks:
      it writes a new value into a <type>Chan</type>
      immediately.</para>
  </sect1>

  <sect1>
    <title>Useful things to know about</title>

    <sect2 id="concurrent.useful.nonstrict">
      <title>MVar and Chan are non-strict</title>

      <para>Like most Haskell container types, both <type>MVar</type>
	and <type>Chan</type> are non-strict: neither evaluates its
	contents.  We mention this not because it's a problem, but
	because it's a common blind spot: people tend to assume that
	these types are strict, perhaps because they're used in the
	<type>IO</type> monad.</para>

      <para>As for other container types, the upshot of a mistaken
	guess about the strictness of an <type>MVar</type> or
	<type>Chan</type> type is often a space or performance leak.
	Here's a plausible scenario to consider.</para>

      <para>We fork off a thread to perform some expensive computation
	on another core.</para>

      &Expensive.hs:notQuiteRight;

      <para>It <emphasis>seems</emphasis> to do something, and puts
	its result back into the <type>MVar</type>.</para>

      &Expensive.hs:expensiveComputation;

      <para>When we take the result from the <type>MVar</type> in the
	parent thread and attempt to do something with it, our thread
	starts computing furiously, because we never forced the
	computation to actually occur in the other thread!</para>

      <para>As usual, the solution is straightforward, once we know
	there's a potential for a problem: we add strictness to the
	forked thread, to ensure that the computation occurs there.
	This strictness is best added in one place, to avoid the
	possibility that we might forget to add it.</para>

      &ModifyMVarStrict.hs:modifyMVar_strict;

      <tip>
	<title>It's always worth checking Hackage</title>

	<para>In the Hackage package database, you will find a
	  library, <code>strict-concurrency</code>, that provides
	  strict versions of the <type>MVar</type> and
	  <type>Chan</type> types.</para>
      </tip>
    </sect2>

    <sect2>
      <title>Chan is unbounded</title>

      <para>Because <function>writeChan</function> always succeeds
	immediately, there is a potential risk to using a
	<type>Chan</type>.  If one thread writes to a
	<type>Chan</type> more often than another thread reads from
	it, the <type>Chan</type> will grow in an unchecked manner:
	unread messages will pile up as the reader falls further and
	further behind.</para>
    </sect2>
  </sect1>

  <sect1>
    <title>Shared-state concurrency is still hard</title>

    <para>Although Haskell has different primitives for sharing data
      between threads than other languages, it still suffers from the
      same fundamental problem: writing correct concurrent programs is
      fiendishly difficult.  Indeed, several pitfalls of concurrent
      programming in other languages apply to Haskell.</para>

    <para>The first of these is <emphasis>deadlock</emphasis>, in
      which two or more threads get stuck forever due to a clash over
      access to shared resources.  One classic way to make a
      multithreaded program deadlock is to forget the order in which
      we must acquire locks.  This kind of bug is so common, it has a
      name: <emphasis>lock order inversion</emphasis>. While Haskell
      doesn't provide locks, the <type>MVar</type> type is prone to
      the order inversion problem. Here's a simple example.</para>

      &LockHierarchy.hs:nestedModification;

    <para>If we run this in &ghci;, it will usually&emdash;but not
      always&emdash;print nothing, indicating that both threads have
      gotten stuck.</para>

    <para>The problem with the <function>nestedModification</function>
      function is easy to spot.  In the first thread, we take the
      <type>MVar</type> <varname>a</varname>, then
      <varname>b</varname>.  In the second, we take
      <varname>b</varname>, then <varname>a</varname>.  If the first
      thread succeeds in taking <varname>a</varname> and the second
      takes <varname>b</varname>, both threads will block: each tries
      to take an <type>MVar</type> that the other has already emptied,
      so neither can make progress.</para>

    <para>In real code, these kinds of inversion problems are much
      more difficult to spot.  The taking of <type>MVar</type>s is
      often spread across several functions in different files, making
      visual inspection more tricky. Worse, these problems are often
      <emphasis>intermittent</emphasis>, which makes them tricky to
      even reproduce, never mind isolate and fix.</para>

    <para>Concurrent software is also prone to
      <emphasis>starvation</emphasis>, in which one thread
      <quote>hogs</quote> a shared resource, preventing another from
      using it.  It's easy to imagine how this might occur: one thread
      calls <function>modifyMVar</function> with a body that executes
      for 100 milliseconds, while another calls
      <function>modifyMVar</function> on the same <type>MVar</type>
      with a body that executes for 1 millisecond.  The second thread
      cannot make progress until the first puts a value back into the
      <type>MVar</type>.</para>

    <para>The non-strict nature of the <type>MVar</type> type can
      either exacerbate or cause a starvation problem.  If we put a
      thunk into an <type>MVar</type> that will be expensive to
      evaluate, and take it out of the <type>MVar</type> in a thread
      that otherwise looks like it <emphasis>ought</emphasis> to be
      cheap, that thread could suddenly become computationally
      expensive if it has to evaluate the thunk.  This makes the
      advice we gave in <xref linkend="concurrent.useful.nonstrict"/>
      particularly relevant.</para>

    <para>Fortunately, the APIs for concurrency that we have covered
      here are by no means the end of the story.  A more recent
      addition to Haskell, Software Transactional Memory, is both
      easier and safer to work with.  We will discuss it in chapter
      XXX.</para>
  </sect1>

  <sect1>
    <title>Exercises</title>

    <qandaset defaultlabel="number">
      <qandaentry>
	<question>
	  <para>The <type>Chan</type> type is implemented using
	    <type>MVar</type>s.  Use <type>MVar</type>s to develop a
	    <type>BoundedChan</type> library.</para>
	</question>
      </qandaentry>

      <qandaentry>
	<question>
	  <para>Your <function>newBoundedChan</function> function
	    should accept an <type>Int</type> parameter, limiting the
	    number of unread items that can be present in a
	    <type>BoundedChan</type> at once.</para>
	</question>
      </qandaentry>

      <qandaentry>
	<question>
	  <para>If this limit is hit, a call to your
	    <function>writeBoundedChan</function> function must block
	    until a reader uses <function>readBoundedChan</function>
	    to consume a value.</para>
	</question>
      </qandaentry>

      <qandaentry>
	<question>
	  <para>Although we've already mentioned the existence of the
	    <code>strict-concurrency</code> package in the Hackage
	    repository, try developing your own, as a wrapper around
	    the built-in <type>MVar</type> type.  Following classic
	    Haskell practice, make your library type safe, so that
	    users cannot accidentally mix uses of strict and
	    non-strict <type>MVar</type>s.</para>
	</question>
      </qandaentry>
    </qandaset>
  </sect1>

<!--

    Basics:
        forkIO
        threadDelay
        async exceptions

    More precise control:
        MVar
        Chan
            - note strictness issues

    SMP programs

    STM locking.

    Parallel strategies.

-->
</chapter>

<!--
local variables: 
sgml-parent-document: ("00book.xml" "book" "chapter")
end:
-->
